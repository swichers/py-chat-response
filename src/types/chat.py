from pydantic import BaseModel
from typing import Optional, List


class ChatRequest(BaseModel):
    """
    Request model for the chat endpoint.

    This model defines the structure of incoming chat requests to the API.
    It contains the user's input text along with optional context information.

    Attributes:
        text (str): The main input text or question from the user.
            This is the primary prompt that will be sent to the AI model.

        context (str, optional): Additional contextual information to prepend to the text.
            This helps provide background information for more relevant responses.
            Defaults to None.

        system_context (str, optional): The machine name of a context file to use
            as system instructions. This customizes the AI's behavior and personality.
            If not provided, the "default" context will be used if available.
            Defaults to None.

    Example:
        {
            "text": "What is the capital of France?",
            "context": "The user is learning about European geography.",
            "system_context": "helpful_tutor"
        }
    """

    text: str
    context: Optional[str] = None
    system_context: Optional[str] = None


class Message(BaseModel):
    """
    Message content model.

    This model represents the actual text content of a message in the chat response.

    Attributes:
        text (str): The text content of the message. This is the generated response
            from the AI model or any other message content.

    Example:
        {
            "text": "The capital of France is Paris."
        }
    """

    text: str


class Output(BaseModel):
    """
    Output message model for chat responses.

    This model represents a single output message in the chat response.
    It includes metadata about the message type, role, and the actual content.

    Attributes:
        type (str): The type of output. Currently always "message" for text responses.

        role (str): The role of the message sender. Currently always "assistant"
            for AI-generated responses.

        system_context (str, optional): The machine name of the system context
            that was used to generate this response. Defaults to None.

        content (Message): The actual message content containing the response text.

    Example:
        {
            "type": "message",
            "role": "assistant",
            "system_context": "helpful_tutor",
            "content": {
                "text": "The capital of France is Paris."
            }
        }
    """

    type: str
    role: str
    system_context: Optional[str] = None
    content: Message


class ChatResponse(BaseModel):
    """
    Response model for the chat endpoint.

    This model defines the structure of the response returned by the chat API.
    It contains a list of output messages generated by the AI.

    Attributes:
        output (List[Output]): A list of output messages. Currently always contains
            a single message with the AI's response, but structured as a list to
            support potential future multi-message responses.

    Example:
        {
            "output": [
                {
                    "type": "message",
                    "role": "assistant",
                    "system_context": "helpful_tutor",
                    "content": {
                        "text": "The capital of France is Paris."
                    }
                }
            ]
        }
    """

    output: List[Output]
