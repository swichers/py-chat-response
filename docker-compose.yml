services:
  py-chat-response:
    build:
      context: .
      dockerfile: Dockerfile
    image: py-chat-response:latest
    container_name: py-chat-response
    ports:
      - "8001:8001"
    environment:
      - LLM_API_KEY=${LLM_API_KEY}
      - LLM_MODEL=${LLM_MODEL:-gemini-2.5-flash-lite}
    volumes:
      - ./contexts:/app/contexts
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8001/health')" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
